<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>MLIR: lib/ExecutionEngine/SparseTensor/NNZ.cpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">MLIR
   &#160;<span id="projectnumber">16.0.0git</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',false,false,'search.php','Search');
});
</script>
<div id="main-nav"></div>
<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_97aefd0d527b934f1d99a682da8fe6a9.html">lib</a></li><li class="navelem"><a class="el" href="dir_9ff4c6dc1720636682ab045c894e9bc5.html">ExecutionEngine</a></li><li class="navelem"><a class="el" href="dir_f4460ae116c9e06657c2919045925830.html">SparseTensor</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">NNZ.cpp</div>  </div>
</div><!--header-->
<div class="contents">
<a href="NNZ_8cpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">//===- NNZ.cpp - NNZ-statistics for direct sparse2sparse conversion -------===//</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment">//</span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment">// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.</span></div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment">// See https://llvm.org/LICENSE.txt for license information.</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment">// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception</span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment">//</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="comment">//===----------------------------------------------------------------------===//</span></div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="comment">//</span></div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="comment">// This file contains method definitions for `SparseTensorNNZ`.</span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="comment">//</span></div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="comment">// This file is part of the lightweight runtime support library for sparse</span></div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="comment">// tensor manipulations.  The functionality of the support library is meant</span></div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="comment">// to simplify benchmarking, testing, and debugging MLIR code operating on</span></div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="comment">// sparse tensors.  However, the provided functionality is **not** part of</span></div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="comment">// core MLIR itself.</span></div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="comment">//</span></div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="comment">//===----------------------------------------------------------------------===//</span></div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;</div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="Storage_8h.html">mlir/ExecutionEngine/SparseTensor/Storage.h</a>&quot;</span></div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;</div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="keyword">using namespace </span><a class="code" href="namespacemlir_1_1sparse__tensor.html">mlir::sparse_tensor</a>;</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="comment">//===----------------------------------------------------------------------===//</span><span class="comment"></span></div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="comment">/// Allocate the statistics structure for the desired sizes and</span></div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="comment">/// sparsity (in the target tensor&#39;s storage-order).  This constructor</span></div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;<span class="comment">/// does not actually populate the statistics, however; for that see</span></div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;<span class="comment">/// `initialize`.</span></div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;<span class="comment">///</span></div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;<span class="comment">/// Precondition: `dimSizes` must not contain zeros.</span></div><div class="line"><a name="l00030"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorNNZ.html#aed0e30b02ffeb755bca21aa129daef01">   30</a></span>&#160;<span class="comment"></span><a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorNNZ.html#aed0e30b02ffeb755bca21aa129daef01">SparseTensorNNZ::SparseTensorNNZ</a>(<span class="keyword">const</span> std::vector&lt;uint64_t&gt; &amp;dimSizes,</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;                                 <span class="keyword">const</span> std::vector&lt;DimLevelType&gt; &amp;sparsity)</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;    : dimSizes(dimSizes), dimTypes(sparsity), nnz(getRank()) {</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;  assert(dimSizes.size() == dimTypes.size() &amp;&amp; <span class="stringliteral">&quot;Rank mismatch&quot;</span>);</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;  <span class="keywordtype">bool</span> alreadyCompressed = <span class="keyword">false</span>;</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;  (<a class="code" href="classvoid.html">void</a>)alreadyCompressed;</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;  uint64_t sz = 1; <span class="comment">// the product of all `dimSizes` strictly less than `r`.</span></div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;  <span class="keywordflow">for</span> (uint64_t rank = <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorNNZ.html#a3b0aa3c094f9b3c77f563c3a9bf2dae6">getRank</a>(), r = 0; r &lt; rank; r++) {</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;    <span class="keyword">const</span> <a class="code" href="namespacemlir_1_1sparse__tensor.html#aa09f02b16598f192895bfa41d8032a95">DimLevelType</a> dlt = sparsity[r];</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;    <span class="keywordflow">if</span> (<a class="code" href="namespacemlir_1_1sparse__tensor.html#ac55329be9bb21947094bd053a2b6f4ce">isCompressedDLT</a>(dlt)) {</div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;      <span class="keywordflow">if</span> (alreadyCompressed)</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;        <a class="code" href="ErrorHandling_8h.html#ab1436fd3501ff57f00a8cdf99238edf1">MLIR_SPARSETENSOR_FATAL</a>(</div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;            <span class="stringliteral">&quot;Multiple compressed layers not currently supported&quot;</span>);</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;      alreadyCompressed = <span class="keyword">true</span>;</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;      nnz[r].resize(sz, 0); <span class="comment">// Both allocate and zero-initialize.</span></div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;    } <span class="keywordflow">else</span> <span class="keywordflow">if</span> (<a class="code" href="namespacemlir_1_1sparse__tensor.html#a53da6b21ba86f146f692f68f8aebd179">isDenseDLT</a>(dlt)) {</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;      <span class="keywordflow">if</span> (alreadyCompressed)</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;        <a class="code" href="ErrorHandling_8h.html#ab1436fd3501ff57f00a8cdf99238edf1">MLIR_SPARSETENSOR_FATAL</a>(</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;            <span class="stringliteral">&quot;Dense after compressed not currently supported&quot;</span>);</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;    } <span class="keywordflow">else</span> <span class="keywordflow">if</span> (<a class="code" href="namespacemlir_1_1sparse__tensor.html#a385e5085ee3fe65734e12c584da4b0e3">isSingletonDLT</a>(dlt)) {</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;      <span class="comment">// Singleton after Compressed causes no problems for allocating</span></div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;      <span class="comment">// `nnz` nor for the yieldPos loop.  This remains true even</span></div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;      <span class="comment">// when adding support for multiple compressed dimensions or</span></div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;      <span class="comment">// for dense-after-compressed.</span></div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;    } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;      <a class="code" href="ErrorHandling_8h.html#ab1436fd3501ff57f00a8cdf99238edf1">MLIR_SPARSETENSOR_FATAL</a>(<span class="stringliteral">&quot;unsupported dimension level type: %d\n&quot;</span>,</div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;                              static_cast&lt;uint8_t&gt;(dlt));</div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;    }</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;    sz = <a class="code" href="namespacemlir_1_1sparse__tensor_1_1detail.html#a6d0a6ea33be89f0b48d34ad50789b299">detail::checkedMul</a>(sz, dimSizes[r]);</div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;  }</div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;}</div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;<span class="comment">/// Lexicographically enumerates all indicies for dimensions strictly</span></div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;<span class="comment">/// less than `stopDim`, and passes their nnz statistic to the callback.</span></div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;<span class="comment">/// Since our use-case only requires the statistic not the coordinates</span></div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;<span class="comment">/// themselves, we do not bother to construct those coordinates.</span></div><div class="line"><a name="l00066"></a><span class="lineno"><a class="line" href="classmlir_1_1sparse__tensor_1_1SparseTensorNNZ.html#a650de56f297c11e34079a2d2b26bd3f4">   66</a></span>&#160;<span class="comment"></span><span class="keywordtype">void</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorNNZ.html#a650de56f297c11e34079a2d2b26bd3f4">SparseTensorNNZ::forallIndices</a>(uint64_t stopDim,</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;                                    <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorNNZ.html#a54fd889b11382256e8f3716b4b7dbc58">SparseTensorNNZ::NNZConsumer</a> yield)<span class="keyword"> const </span>{</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;  assert(stopDim &lt; <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorNNZ.html#a3b0aa3c094f9b3c77f563c3a9bf2dae6">getRank</a>() &amp;&amp; <span class="stringliteral">&quot;Dimension out of bounds&quot;</span>);</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;  assert(<a class="code" href="namespacemlir_1_1sparse__tensor.html#ac55329be9bb21947094bd053a2b6f4ce">isCompressedDLT</a>(dimTypes[stopDim]) &amp;&amp;</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;         <span class="stringliteral">&quot;Cannot look up non-compressed dimensions&quot;</span>);</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;  <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorNNZ.html#a650de56f297c11e34079a2d2b26bd3f4">forallIndices</a>(yield, stopDim, 0, 0);</div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;}</div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;<span class="comment">/// Adds a new element (i.e., increment its statistics).  We use</span></div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;<span class="comment">/// a method rather than inlining into the lambda in `initialize`,</span></div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;<span class="comment">/// to avoid spurious templating over `V`.  And this method is private</span></div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;<span class="comment">/// to avoid needing to re-assert validity of `ind` (which is guaranteed</span></div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;<span class="comment">/// by `forallElements`).</span></div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;<span class="comment"></span><span class="keywordtype">void</span> SparseTensorNNZ::add(<span class="keyword">const</span> std::vector&lt;uint64_t&gt; &amp;ind) {</div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;  uint64_t parentPos = 0;</div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;  <span class="keywordflow">for</span> (uint64_t rank = <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorNNZ.html#a3b0aa3c094f9b3c77f563c3a9bf2dae6">getRank</a>(), r = 0; r &lt; rank; ++r) {</div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;    <span class="keywordflow">if</span> (<a class="code" href="namespacemlir_1_1sparse__tensor.html#ac55329be9bb21947094bd053a2b6f4ce">isCompressedDLT</a>(dimTypes[r]))</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;      nnz[r][parentPos]++;</div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;    parentPos = parentPos * dimSizes[r] + ind[r];</div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;  }</div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;}</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;<span class="comment">/// Recursive component of the public `forallIndices`.</span></div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;<span class="comment"></span><span class="keywordtype">void</span> <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorNNZ.html#a650de56f297c11e34079a2d2b26bd3f4">SparseTensorNNZ::forallIndices</a>(<a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorNNZ.html#a54fd889b11382256e8f3716b4b7dbc58">SparseTensorNNZ::NNZConsumer</a> yield,</div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;                                    uint64_t stopDim, uint64_t parentPos,</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;                                    uint64_t d)<span class="keyword"> const </span>{</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;  assert(d &lt;= stopDim);</div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;  <span class="keywordflow">if</span> (d == stopDim) {</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;    assert(parentPos &lt; nnz[d].size() &amp;&amp; <span class="stringliteral">&quot;Cursor is out of range&quot;</span>);</div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;    yield(nnz[d][parentPos]);</div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;  } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;    <span class="keyword">const</span> uint64_t sz = dimSizes[d];</div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;    <span class="keyword">const</span> uint64_t pstart = parentPos * sz;</div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;    <span class="keywordflow">for</span> (uint64_t i = 0; i &lt; sz; i++)</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;      <a class="code" href="classmlir_1_1sparse__tensor_1_1SparseTensorNNZ.html#a650de56f297c11e34079a2d2b26bd3f4">forallIndices</a>(yield, stopDim, pstart + i, d + 1);</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;  }</div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;}</div><div class="ttc" id="classmlir_1_1sparse__tensor_1_1SparseTensorNNZ_html_a3b0aa3c094f9b3c77f563c3a9bf2dae6"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorNNZ.html#a3b0aa3c094f9b3c77f563c3a9bf2dae6">mlir::sparse_tensor::SparseTensorNNZ::getRank</a></div><div class="ttdeci">uint64_t getRank() const</div><div class="ttdoc">Returns the rank of the target tensor. </div><div class="ttdef"><b>Definition:</b> <a href="Storage_8h_source.html#l00697">Storage.h:697</a></div></div>
<div class="ttc" id="classvoid_html"><div class="ttname"><a href="classvoid.html">void</a></div></div>
<div class="ttc" id="classmlir_1_1sparse__tensor_1_1SparseTensorNNZ_html_a54fd889b11382256e8f3716b4b7dbc58"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorNNZ.html#a54fd889b11382256e8f3716b4b7dbc58">mlir::sparse_tensor::SparseTensorNNZ::NNZConsumer</a></div><div class="ttdeci">const std::function&lt; void(uint64_t)&gt; &amp; NNZConsumer</div><div class="ttdoc">The type of callback functions which receive an nnz-statistic. </div><div class="ttdef"><b>Definition:</b> <a href="Storage_8h_source.html#l00711">Storage.h:711</a></div></div>
<div class="ttc" id="namespacemlir_1_1sparse__tensor_html_ac55329be9bb21947094bd053a2b6f4ce"><div class="ttname"><a href="namespacemlir_1_1sparse__tensor.html#ac55329be9bb21947094bd053a2b6f4ce">mlir::sparse_tensor::isCompressedDLT</a></div><div class="ttdeci">constexpr bool isCompressedDLT(DimLevelType dlt)</div><div class="ttdoc">Check if the DimLevelType is compressed (regardless of properties). </div><div class="ttdef"><b>Definition:</b> <a href="Enums_8h_source.html#l00184">Enums.h:184</a></div></div>
<div class="ttc" id="namespacemlir_1_1sparse__tensor_html_a385e5085ee3fe65734e12c584da4b0e3"><div class="ttname"><a href="namespacemlir_1_1sparse__tensor.html#a385e5085ee3fe65734e12c584da4b0e3">mlir::sparse_tensor::isSingletonDLT</a></div><div class="ttdeci">constexpr bool isSingletonDLT(DimLevelType dlt)</div><div class="ttdoc">Check if the DimLevelType is singleton (regardless of properties). </div><div class="ttdef"><b>Definition:</b> <a href="Enums_8h_source.html#l00190">Enums.h:190</a></div></div>
<div class="ttc" id="classmlir_1_1sparse__tensor_1_1SparseTensorNNZ_html_aed0e30b02ffeb755bca21aa129daef01"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorNNZ.html#aed0e30b02ffeb755bca21aa129daef01">mlir::sparse_tensor::SparseTensorNNZ::SparseTensorNNZ</a></div><div class="ttdeci">SparseTensorNNZ(const std::vector&lt; uint64_t &gt; &amp;dimSizes, const std::vector&lt; DimLevelType &gt; &amp;sparsity)</div><div class="ttdoc">Allocates the statistics structure for the desired sizes and sparsity (in the target tensor&amp;#39;s storage...</div><div class="ttdef"><b>Definition:</b> <a href="NNZ_8cpp_source.html#l00030">NNZ.cpp:30</a></div></div>
<div class="ttc" id="Storage_8h_html"><div class="ttname"><a href="Storage_8h.html">Storage.h</a></div></div>
<div class="ttc" id="namespacemlir_1_1sparse__tensor_1_1detail_html_a6d0a6ea33be89f0b48d34ad50789b299"><div class="ttname"><a href="namespacemlir_1_1sparse__tensor_1_1detail.html#a6d0a6ea33be89f0b48d34ad50789b299">mlir::sparse_tensor::detail::checkedMul</a></div><div class="ttdeci">uint64_t checkedMul(uint64_t lhs, uint64_t rhs)</div><div class="ttdoc">A version of operator* on uint64_t which guards against overflows (when assertions are enabled)...</div><div class="ttdef"><b>Definition:</b> <a href="CheckedMul_8h_source.html#l00038">CheckedMul.h:38</a></div></div>
<div class="ttc" id="classmlir_1_1sparse__tensor_1_1SparseTensorNNZ_html_a650de56f297c11e34079a2d2b26bd3f4"><div class="ttname"><a href="classmlir_1_1sparse__tensor_1_1SparseTensorNNZ.html#a650de56f297c11e34079a2d2b26bd3f4">mlir::sparse_tensor::SparseTensorNNZ::forallIndices</a></div><div class="ttdeci">void forallIndices(uint64_t stopDim, NNZConsumer yield) const</div><div class="ttdoc">Lexicographically enumerates all indicies for dimensions strictly less than stopDim, and passes their nnz statistic to the callback. </div><div class="ttdef"><b>Definition:</b> <a href="NNZ_8cpp_source.html#l00066">NNZ.cpp:66</a></div></div>
<div class="ttc" id="namespacemlir_1_1sparse__tensor_html_a53da6b21ba86f146f692f68f8aebd179"><div class="ttname"><a href="namespacemlir_1_1sparse__tensor.html#a53da6b21ba86f146f692f68f8aebd179">mlir::sparse_tensor::isDenseDLT</a></div><div class="ttdeci">constexpr bool isDenseDLT(DimLevelType dlt)</div><div class="ttdoc">Check if the DimLevelType is dense. </div><div class="ttdef"><b>Definition:</b> <a href="Enums_8h_source.html#l00175">Enums.h:175</a></div></div>
<div class="ttc" id="namespacemlir_1_1sparse__tensor_html_aa09f02b16598f192895bfa41d8032a95"><div class="ttname"><a href="namespacemlir_1_1sparse__tensor.html#aa09f02b16598f192895bfa41d8032a95">mlir::sparse_tensor::DimLevelType</a></div><div class="ttdeci">DimLevelType</div><div class="ttdoc">This enum defines all the sparse representations supportable by the SparseTensor dialect. </div><div class="ttdef"><b>Definition:</b> <a href="Enums_8h_source.html#l00146">Enums.h:146</a></div></div>
<div class="ttc" id="ErrorHandling_8h_html_ab1436fd3501ff57f00a8cdf99238edf1"><div class="ttname"><a href="ErrorHandling_8h.html#ab1436fd3501ff57f00a8cdf99238edf1">MLIR_SPARSETENSOR_FATAL</a></div><div class="ttdeci">#define MLIR_SPARSETENSOR_FATAL(...)</div><div class="ttdoc">This macro helps minimize repetition of the printf-and-exit idiom, as well as ensuring that we print ...</div><div class="ttdef"><b>Definition:</b> <a href="ErrorHandling_8h_source.html#l00037">ErrorHandling.h:37</a></div></div>
<div class="ttc" id="namespacemlir_1_1sparse__tensor_html"><div class="ttname"><a href="namespacemlir_1_1sparse__tensor.html">mlir::sparse_tensor</a></div><div class="ttdef"><b>Definition:</b> <a href="Enums_8h_source.html#l00038">Enums.h:38</a></div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Fri Nov 4 2022 16:35:27 for MLIR by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
